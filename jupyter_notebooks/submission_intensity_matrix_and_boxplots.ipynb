{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.colors as clr\n",
    "import logging \n",
    "import sys\n",
    "from functools import reduce\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import chart_studio.plotly as py\n",
    "from pybedtools import BedTool\n",
    "import pybedtools as pybt\n",
    "import seaborn as sb\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summed_matrix(working_directory,samplenames):\n",
    "    \"\"\"\n",
    "    Function to summarize intensity matrices\n",
    "    \"\"\"\n",
    "    relative_path = \"intensity_matrix/intensity_matrix.csv\"\n",
    "    summed_matrix = np.zeros((13551,13551))\n",
    "    for i in samplenames:\n",
    "        matrix_path = os.path.join(working_directory,i,relative_path)\n",
    "        matrix_df = pd.read_csv(matrix_path,sep=\";\",header=0)\n",
    "        matrix_df = matrix_df[[\"start\",\"end\",\"n_reads\"]]\n",
    "        for start,end,n_reads in zip(matrix_df[\"start\"],matrix_df[\"end\"],matrix_df[\"n_reads\"]):\n",
    "            summed_matrix[start][end] += n_reads      \n",
    "    summed_dbscan_matrix = np.array([[int(x),int(y),int(summed_matrix[x][y])] for x, y in zip(*np.nonzero(summed_matrix))])\n",
    "    summed_df = pd.DataFrame(summed_dbscan_matrix)\n",
    "    summed_df.columns = [\"start\",\"end\",\"n_reads\"]\n",
    "    return summed_matrix,summed_dbscan_matrix,summed_df\n",
    "\n",
    "def plot_matrix(\n",
    "    legend_names:list,dbscan_matrices: list, color_samples: list, template_df_name: str, output: str, with_lines:bool=True):\n",
    "    \"\"\"\n",
    "    Function to plot several matrices above one another and colorcode them\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,10), dpi=500)\n",
    "    legend_dots = []\n",
    "    template_df = pd.read_csv(template_df_name, sep=\";\", header=0, index_col=None)\n",
    "    template_df = template_df[template_df[\"Fragment\"].isin([\"18S\", \"28S\", \"5-8S\", \"5ETS\", \"ITS1\", \"ITS2\", \"ITS3\", \"3ETS\"])]\n",
    "    for legend_name,dbscan_matrix,color_sample in zip(legend_names,dbscan_matrices,color_samples):\n",
    "        dbscan_df = pd.DataFrame(dbscan_matrix)\n",
    "        start_points = dbscan_df.iloc[:, 0]\n",
    "        end_points = dbscan_df.iloc[:, 1]\n",
    "        maximum = dbscan_df.iloc[:, 2].max()\n",
    "        alphas = dbscan_df.iloc[:, 2] / maximum\n",
    "        alphas = alphas + 0.01\n",
    "        alphas[alphas > 1] = 1\n",
    "        ax.scatter(\n",
    "            x=start_points, y=end_points, alpha=alphas, s=0.5, c=color_sample, label=legend_name\n",
    "        )\n",
    "        legend_dots.append(mlines.Line2D([], [], color=color_sample, marker='o', linestyle='None', markersize=5, label=legend_name))\n",
    "    ax.legend(handles=legend_dots,loc='lower right')\n",
    "    if with_lines:\n",
    "        for template, start, end in zip(\n",
    "            template_df[\"Fragment\"], template_df[\"Start\"], template_df[\"End\"]\n",
    "        ):\n",
    "            ax.hlines(\n",
    "                y=end, xmin=start, xmax=end, color=\"red\", linewidth=1, linestyles=\"dashed\"\n",
    "            )\n",
    "            ax.vlines(\n",
    "                x=start, ymin=start, ymax=end, color=\"red\", linewidth=1, linestyles=\"dashed\"\n",
    "            )\n",
    "            ax.hlines(\n",
    "                y=start, xmin=start, xmax=end, color=\"red\", linewidth=1, linestyles=\"dashed\"\n",
    "            )\n",
    "            ax.vlines(\n",
    "                x=end, ymin=start, ymax=end, color=\"red\", linewidth=1, linestyles=\"dashed\"\n",
    "            )\n",
    "            text_x_position = int(start + ((end - start) * 0.5)) - (len(template) * 50)\n",
    "            text_y_position = start - 250\n",
    "            ax.text(x=text_x_position, y=text_y_position, s=template, fontsize=\"x-small\")\n",
    "    ax.set_xlabel(\"Start sites\")\n",
    "    ax.set_ylabel(\"End sites\")\n",
    "    fig.show()\n",
    "    plt.savefig(f\"{output}/intensity_matrix_summed.png\", format=\"png\",dpi=500)\n",
    "    \n",
    "    \n",
    "def plot_difference_matrix(matrix_sample:np.array,matrix_reference:np.array, condition_sample:str, condition_reference:str,template_df_name:str,with_lines:bool=True):\n",
    "    #viridis\n",
    "    maximum_sample = matrix_sample.max()\n",
    "    matrix_sample_norm = matrix_sample / maximum_sample\n",
    "    \n",
    "    maximum_reference = matrix_reference.max()\n",
    "    matrix_reference_norm = matrix_reference / maximum_reference\n",
    "\n",
    "    matrix_difference = matrix_sample_norm - matrix_reference_norm\n",
    "    print(matrix_difference[matrix_difference < 0])\n",
    "    print(matrix_difference[matrix_difference > 0])\n",
    "    #matrix_difference += 1\n",
    "    #matrix_difference = matrix_difference / \n",
    "    \n",
    "    \n",
    "    difference_dbscan_matrix = np.array([[int(x),int(y),float(matrix_difference[x][y])] for x, y in zip(*np.nonzero(matrix_difference))])\n",
    "    difference_df = pd.DataFrame(difference_dbscan_matrix)\n",
    "    difference_df.columns = [\"start\",\"end\",\"alpha\"]\n",
    "    difference_df[\"alpha\"] = [i - 0.2 if i < 0 else i + 0.2 for i in difference_df[\"alpha\"]]\n",
    "    difference_df[\"alpha\"] = (difference_df[\"alpha\"] + 1) / 2\n",
    "    start_points = difference_df.start\n",
    "    end_points = difference_df.end\n",
    "    alphas = difference_df.alpha\n",
    "    alphas[alphas > 1] = 1\n",
    "    alphas[alphas < 0] = 0\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,10), dpi=500)\n",
    "    template_df = pd.read_csv(template_df_name, sep=\";\", header=0, index_col=None)\n",
    "    template_df = template_df[template_df[\"Fragment\"].isin([\"18S\", \"28S\", \"5-8S\", \"5ETS\", \"ITS1\", \"ITS2\", \"ITS3\", \"3ETS\"])]\n",
    "    \n",
    "    ax.scatter(x=start_points, y=end_points, alpha=alphas, s=1,c=alphas,cmap=\"PiYG\")\n",
    "    ax.legend(loc='lower right')\n",
    "    if with_lines:\n",
    "        for template, start, end in zip(\n",
    "            template_df[\"Fragment\"], template_df[\"Start\"], template_df[\"End\"]\n",
    "        ):\n",
    "            ax.hlines(\n",
    "                y=end, xmin=start, xmax=end, color=\"red\", linewidth=1, linestyles=\"dashed\"\n",
    "            )\n",
    "            ax.vlines(\n",
    "                x=start, ymin=start, ymax=end, color=\"red\", linewidth=1, linestyles=\"dashed\"\n",
    "            )\n",
    "            ax.hlines(\n",
    "                y=start, xmin=start, xmax=end, color=\"red\", linewidth=1, linestyles=\"dashed\"\n",
    "            )\n",
    "            ax.vlines(\n",
    "                x=end, ymin=start, ymax=end, color=\"red\", linewidth=1, linestyles=\"dashed\"\n",
    "            )\n",
    "            text_x_position = int(start + ((end - start) * 0.5)) - (len(template) * 50)\n",
    "            text_y_position = start - 250\n",
    "            ax.text(x=text_x_position, y=text_y_position, s=template, fontsize=\"x-small\")\n",
    "    fig.show()\n",
    "\n",
    "def plot_unique_matrix(matrix_samples:np.array,condition_samples:list,color_samples:list,template_df_name:str,with_lines:bool=True):\n",
    "    template_df = pd.read_csv(template_df_name, sep=\";\", header=0, index_col=None)\n",
    "    template_df = template_df[template_df[\"Fragment\"].isin([\"18S\", \"28S\", \"5-8S\", \"5ETS\", \"ITS1\", \"ITS2\", \"ITS3\", \"3ETS\"])]\n",
    "    unique_dict = dict()\n",
    "    normalized_samples_matrices = []\n",
    "    colors = color_samples\n",
    "    conditions = condition_samples\n",
    "    for matrix_sample in matrix_samples:\n",
    "        maximum_sample = matrix_sample.max()\n",
    "        matrix_sample_norm = matrix_sample / maximum_sample\n",
    "        normalized_samples_matrices.append(matrix_sample_norm)\n",
    "    for normalized_sample_matrix,color,condition in zip(normalized_samples_matrices, colors, conditions):\n",
    "        for x,y in zip(*np.nonzero(normalized_sample_matrix)):\n",
    "            if f\"{x}:{y}\" not in unique_dict.keys():\n",
    "                unique_dict[f\"{x}:{y}\"] = list()\n",
    "                unique_dict[f\"{x}:{y}\"].append((color,normalized_sample_matrix[x][y],condition))\n",
    "            else:\n",
    "                unique_dict[f\"{x}:{y}\"].append((color,normalized_sample_matrix[x][y],condition))\n",
    "    entries = []\n",
    "    for index,key in enumerate(list(unique_dict.keys())):\n",
    "        x = int(key.split(\":\")[0])\n",
    "        y = int(key.split(\":\")[1])\n",
    "        color_alpha_condition_tuple = unique_dict[f\"{x}:{y}\"]\n",
    "        if len(color_alpha_condition_tuple) > 1:\n",
    "            color = \"black\"\n",
    "            alphas = np.array([a[1] for a in color_alpha_condition_tuple])\n",
    "            alpha = alphas.mean()\n",
    "            #alpha=0\n",
    "            condition = \"Diverse\"\n",
    "            #entry = [x,y,alpha,color,condition]\n",
    "            #entries.append(entry)\n",
    "        elif len(color_alpha_condition_tuple) == 1:\n",
    "            color=color_alpha_condition_tuple[0][0]\n",
    "            alpha=color_alpha_condition_tuple[0][1]\n",
    "            #alpha=1\n",
    "            condition=color_alpha_condition_tuple[0][2]\n",
    "            entry = [x,y,alpha,color,condition]\n",
    "            entries.append(entry)\n",
    "    \n",
    "    condition_name = \"\"\n",
    "    for name in condition_samples:\n",
    "        spaceless_name = name.replace(\" \",\"_\")\n",
    "        condition_name = f\"{condition_name}{spaceless_name}_\"\n",
    "    #fig.savefig(f\"{condition_name}_RNA45SN1_intensity_matrix.png\",format = \"png\",dpi=500)\n",
    "    #coordinates for 5'ETS,18S,ITS1,5.8S,ITS2,28S,3'ETS,small_processome,big_processome\n",
    "    coordinate_names = [\"5ETS\",\"18S\",\"ITS1+5.8S+ITS2\",\"28S\",\"3ETS\",\"small_processome\",\"big_processome\",\"45S\"]\n",
    "    coordinate_tuples = [(-400,4054),(3256,5924),(5124,8325),(7525,13300),(12563,13900),(-200,7100),(6400,13900),(-400,14000)]\n",
    "    plot_df = pd.DataFrame(entries, columns=[\"start\",\"end\",\"alpha\",\"color\",\"condition\"])\n",
    "    for coordinate_tuple,coordinate_name in zip(coordinate_tuples,coordinate_names):\n",
    "        temp_plot_df = plot_df[plot_df[\"start\"] >= coordinate_tuple[0]]\n",
    "        temp_plot_df = temp_plot_df[temp_plot_df[\"end\"] <= coordinate_tuple[1]]\n",
    "        start_points = np.array(temp_plot_df[\"start\"])\n",
    "        end_points = np.array(temp_plot_df[\"end\"])\n",
    "        alphas = np.array(temp_plot_df[\"alpha\"] + 0.01)\n",
    "        alphas[alphas > 1] = 1\n",
    "        dot_colors = np.array(temp_plot_df[\"color\"])\n",
    "        conditions = np.array(temp_plot_df[\"condition\"])\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10,10), dpi=500)\n",
    "        legend_dots = []\n",
    "        if not coordinate_name == \"45S\":\n",
    "            with_lines = True\n",
    "        else:\n",
    "            with_lines = False\n",
    "        if with_lines:\n",
    "            for template, start, end in zip(\n",
    "                template_df[\"Fragment\"], template_df[\"Start\"], template_df[\"End\"]\n",
    "            ):\n",
    "                if start >= coordinate_tuple[0] and end <= coordinate_tuple[1]:\n",
    "                    ax.hlines(\n",
    "                        y=end, xmin=start, xmax=end, color=\"red\", linewidth=1, linestyles=\"dashed\", alpha = 0.08\n",
    "                    )\n",
    "                    ax.vlines(\n",
    "                        x=start, ymin=start, ymax=end, color=\"red\", linewidth=1, linestyles=\"dashed\", alpha = 0.08\n",
    "                    )\n",
    "                    ax.hlines(\n",
    "                        y=start, xmin=start, xmax=end, color=\"red\", linewidth=1, linestyles=\"dashed\", alpha = 0.08\n",
    "                    )\n",
    "                    ax.vlines(\n",
    "                        x=end, ymin=start, ymax=end, color=\"red\", linewidth=1, linestyles=\"dashed\", alpha = 0.08\n",
    "                    )\n",
    "                    text_x_position = int(start + ((end - start) * 0.5)) - ((coordinate_tuple[1]-coordinate_tuple[0]) * 0.01)\n",
    "                    text_y_position = start - ((coordinate_tuple[1]-coordinate_tuple[0]) * 0.01)\n",
    "                    ax.text(x=text_x_position, y=text_y_position, s=template, fontsize=\"x-small\")\n",
    "        ax.scatter(x=start_points, y=end_points, alpha=alphas, s=0.5, c=dot_colors)\n",
    "        #color_samples.append(\"black\")\n",
    "        #condition_samples.append(\"Diverse\")\n",
    "        for legend_color,legend_condition in zip(color_samples,condition_samples):\n",
    "            legend_dots.append(mlines.Line2D([], [], color=legend_color, marker='o', linestyle='None', markersize=5, label=legend_condition))\n",
    "        ax.legend(handles=legend_dots,loc='lower right')\n",
    "        \n",
    "        ax.set_xlabel(\"Start sites\")\n",
    "        ax.set_ylabel(\"End sites\")\n",
    "        ax.set_xlim(coordinate_tuple)\n",
    "        ax.set_ylim(coordinate_tuple)\n",
    "        #plt.show()\n",
    "        if coordinate_name == \"45S\":\n",
    "            fig.savefig(f\"./{condition_name}_{coordinate_name}_intensity_matrix.png\",format = \"png\",dpi=1000)\n",
    "        else:\n",
    "            fig.savefig(f\"./{condition_name}_{coordinate_name}_intensity_matrix.svg\",format = \"svg\")\n",
    "    #ax.set_xlim(-400,14000)\n",
    "    #ax.set_ylim(-400,14000)\n",
    "    fig.show()\n",
    "    #legend_dots.append(mlines.Line2D([], [], color=color_sample, marker='o', linestyle='None', markersize=5, label=legend_name))\n",
    "    #ax.legend(handles=legend_dots,loc='lower right')\n",
    "\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define path to list with rRNA intermediates from literature\n",
    "template_name = \"/home/stefan/wf-nanoribolyzer/references/Literature_Fragments_and_cut_sites_RNA45SN1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize intensity matrices of UTP18 mutant data\n",
    "\n",
    "UTP18_wd = \"/home/stefan/Synology/Data_nano_ribolyzer/20240314_Ribolyzer_UTP18/\"\n",
    "\n",
    "UTP18_IVPA_Nuc_samples = [\"20240314_Ribolyzer_UTP18_R10_IVPA_Nuc\",\"20240314_Ribolyzer_UTP18_R11_IVPA_Nuc\",\"20240314_Ribolyzer_UTP18_R12_IVPA_Nuc\"]\n",
    "UTP18_IVPA_Nuc_matrix,UTP18_IVPA_Nuc_dbscan_matrix,UTP18_IVPA_Nuc_df = create_summed_matrix(UTP18_wd,UTP18_IVPA_Nuc_samples)\n",
    "\n",
    "\n",
    "UTP18_IVPA_Cyt_samples = [\"20240314_Ribolyzer_UTP18_R7_IVPA_Cyt\",\"20240314_Ribolyzer_UTP18_R8_IVPA_Cyt\",\"20240314_Ribolyzer_UTP18_R9_IVPA_Cyt\"]\n",
    "UTP18_IVPA_Cyt_matrix,UTP18_IVPA_Cyt_dbscan_matrix,UTP18_IVPA_Cyt_df = create_summed_matrix(UTP18_wd,UTP18_IVPA_Cyt_samples)\n",
    "\n",
    "UTP18_NP_Nuc_samples = [\"20240314_Ribolyzer_UTP18_R4_NP_Nuc\",\"20240314_Ribolyzer_UTP18_R5_NP_Nuc\",\"20240314_Ribolyzer_UTP18_R6_NP_Nuc\"]\n",
    "UTP18_NP_Nuc_matrix,UTP18_NP_Nuc_dbscan_matrix,UTP18_NP_Nuc_df = create_summed_matrix(UTP18_wd,UTP18_NP_Nuc_samples)\n",
    "\n",
    "UTP18_NP_Cyt_samples = [\"20240314_Ribolyzer_UTP18_R1_NP_Cyt\",\"20240314_Ribolyzer_UTP18_R2_NP_Cyt\",\"20240314_Ribolyzer_UTP18_R3_NP_Cyt\"]\n",
    "UTP18_NP_Cyt_matrix,UTP18_NP_Cyt_dbscan_matrix,UTP18_NP_Cyt_df = create_summed_matrix(UTP18_wd,UTP18_NP_Cyt_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize intensity matrices of Las1L mutant data\n",
    "Las1L_wd = \"/home/stefan/Synology/Data_nano_ribolyzer/Las1L_NanoRibolyzer/\"\n",
    "\n",
    "Las1L_IVPA_Nuc_samples = [\"IVPA_Las1L_Nucleus1\",\"IVPA_Las1L_Nucleus2\",\"IVPA_Las1L_Nucleus3\"]\n",
    "Las1L_IVPA_Nuc_matrix,Las1L_IVPA_Nuc_dbscan_matrix,Las1L_IVPA_Nuc_df = create_summed_matrix(Las1L_wd,Las1L_IVPA_Nuc_samples)\n",
    "\n",
    "\n",
    "Las1L_IVPA_Cyt_samples = [\"IVPA_Las1L_Cytoplasm1\",\"IVPA_Las1L_Cytoplasm2\",\"IVPA_Las1L_Cytoplasm3\"]\n",
    "Las1L_IVPA_Cyt_matrix,Las1L_IVPA_Cyt_dbscan_matrix,Las1L_IVPA_Cyt_df = create_summed_matrix(Las1L_wd,Las1L_IVPA_Cyt_samples)\n",
    "\n",
    "Las1L_NP_Nuc_samples = [\"NP_Las1L_Nucleus1\",\"NP_Las1L_Nucleus2\",\"NP_Las1L_Nucleus3\"]\n",
    "Las1L_NP_Nuc_matrix,Las1L_NP_Nuc_dbscan_matrix,Las1L_NP_Nuc_df = create_summed_matrix(Las1L_wd,Las1L_NP_Nuc_samples)\n",
    "\n",
    "Las1L_NP_Cyt_samples = [\"NP_Las1L_Cytoplasm1\",\"NP_Las1L_Cytoplasm2\",\"NP_Las1L_Cytoplasm3\"]\n",
    "Las1L_NP_Cyt_matrix,Las1L_NP_Cyt_dbscan_matrix,Las1L_NP_Cyt_df = create_summed_matrix(Las1L_wd,Las1L_NP_Cyt_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize intensity matrices of WBSCR22 mutant data\n",
    "\n",
    "WBSCR22_wd = \"/home/stefan/Synology/Data_nano_ribolyzer/WBSCR22_NanoRibolyzer/\"\n",
    "\n",
    "WBSCR22_IVPA_Nuc_samples = [\"IVPA_WBSCR22_Nucleus1\",\"IVPA_WBSCR22_Nucleus2\",\"IVPA_WBSCR22_Nucleus3\"]\n",
    "WBSCR22_IVPA_Nuc_matrix,WBSCR22_IVPA_Nuc_dbscan_matrix,WBSCR22_IVPA_Nuc_df = create_summed_matrix(WBSCR22_wd,WBSCR22_IVPA_Nuc_samples)\n",
    "\n",
    "\n",
    "WBSCR22_IVPA_Cyt_samples = [\"IVPA_WBSCR22_Cytoplasm1\",\"IVPA_WBSCR22_Cytoplasm2\",\"IVPA_WBSCR22_Cytoplasm3\"]\n",
    "WBSCR22_IVPA_Cyt_matrix,WBSCR22_IVPA_Cyt_dbscan_matrix,WBSCR22_IVPA_Cyt_df = create_summed_matrix(WBSCR22_wd,WBSCR22_IVPA_Cyt_samples)\n",
    "\n",
    "WBSCR22_NP_Nuc_samples = [\"NP_WBSCR22_Nucleus1\",\"NP_WBSCR22_Nucleus2\",\"NP_WBSCR22_Nucleus3\"]\n",
    "WBSCR22_NP_Nuc_matrix,WBSCR22_NP_Nuc_dbscan_matrix,WBSCR22_NP_Nuc_df = create_summed_matrix(WBSCR22_wd,WBSCR22_NP_Nuc_samples)\n",
    "\n",
    "WBSCR22_NP_Cyt_samples = [\"NP_WBSCR22_Cytoplasm1\",\"NP_WBSCR22_Cytoplasm2\",\"NP_WBSCR22_Cytoplasm3\"]\n",
    "WBSCR22_NP_Cyt_matrix,WBSCR22_NP_Cyt_dbscan_matrix,WBSCR22_NP_Cyt_df = create_summed_matrix(WBSCR22_wd,WBSCR22_NP_Cyt_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize intensity matrices of Ctrl mutant data\n",
    "Ctrl_wd = \"/home/stefan/Synology/Data_nano_ribolyzer/20240314_Ribolyzer_Ctrl/\"\n",
    "\n",
    "Ctrl_IVPA_Nuc_samples = [\"20240314_Ribolyzer_Ctrl_R10_IVPA_Nuc\",\"20240314_Ribolyzer_Ctrl_R11_IVPA_Nuc\",\"20240314_Ribolyzer_Ctrl_R12_IVPA_Nuc\"]\n",
    "Ctrl_IVPA_Nuc_matrix,Ctrl_IVPA_Nuc_dbscan_matrix,Ctrl_IVPA_Nuc_df = create_summed_matrix(Ctrl_wd,Ctrl_IVPA_Nuc_samples)\n",
    "\n",
    "\n",
    "Ctrl_IVPA_Cyt_samples = [\"20240314_Ribolyzer_Ctrl_R7_IVPA_Cyt\",\"20240314_Ribolyzer_Ctrl_R8_IVPA_Cyt\",\"20240314_Ribolyzer_Ctrl_R9_IVPA_Cyt\"]\n",
    "Ctrl_IVPA_Cyt_matrix,Ctrl_IVPA_Cyt_dbscan_matrix,Ctrl_IVPA_Cyt_df = create_summed_matrix(Ctrl_wd,Ctrl_IVPA_Cyt_samples)\n",
    "\n",
    "Ctrl_NP_Nuc_samples = [\"20240314_Ribolyzer_Ctrl_R4_NP_Nuc\",\"20240314_Ribolyzer_Ctrl_R5_NP_Nuc\",\"20240314_Ribolyzer_Ctrl_R6_NP_Nuc\"]\n",
    "Ctrl_NP_Nuc_matrix,Ctrl_NP_Nuc_dbscan_matrix,Ctrl_NP_Nuc_df = create_summed_matrix(Ctrl_wd,Ctrl_NP_Nuc_samples)\n",
    "\n",
    "Ctrl_NP_Cyt_samples = [\"20240314_Ribolyzer_Ctrl_R1_NP_Cyt\",\"20240314_Ribolyzer_Ctrl_R2_NP_Cyt\",\"20240314_Ribolyzer_Ctrl_R3_NP_Cyt\"]\n",
    "Ctrl_NP_Cyt_matrix,Ctrl_NP_Cyt_dbscan_matrix,Ctrl_NP_Cyt_df = create_summed_matrix(Ctrl_wd,Ctrl_NP_Cyt_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize intensity matrices of SN1\n",
    "SN1_wd = \"/home/stefan/Synology/Data_nano_ribolyzer/NP_IVPA_SN1-3_R10/\"\n",
    "\n",
    "SN1_IVPA_samples = [\"20231123_SNExp_18Bc_IVPA_SN1_R1\",\"20231123_SNExp_18Bc_IVPA_SN1_R2\",\"20231123_SNExp_18Bc_IVPA_SN1_R3\"]\n",
    "SN1_IVPA_matrix,SN1_IVPA_dbscan_matrix,SN1_IVPA_df = create_summed_matrix(SN1_wd,SN1_IVPA_samples)\n",
    "\n",
    "SN1_NP_samples = [\"20231123_SNExp_18Bc_NP_SN1_R1\",\"20231123_SNExp_18Bc_NP_SN1_R2\",\"20231123_SNExp_18Bc_NP_SN1_R3\"]\n",
    "SN1_NP_matrix,SN1_NP_dbscan_matrix,SN1_NP_df = create_summed_matrix(SN1_wd,SN1_NP_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize intensity matrices of SN2\n",
    "SN2_wd = \"/home/stefan/Synology/Data_nano_ribolyzer/NP_IVPA_SN1-3_R10/\"\n",
    "\n",
    "SN2_IVPA_samples = [\"20231123_SNExp_18Bc_IVPA_SN2_R1\",\"20231123_SNExp_18Bc_IVPA_SN2_R2\",\"20231123_SNExp_18Bc_IVPA_SN2_R3\"]\n",
    "SN2_IVPA_matrix,SN2_IVPA_dbscan_matrix,SN2_IVPA_df = create_summed_matrix(SN2_wd,SN2_IVPA_samples)\n",
    "\n",
    "SN2_NP_samples = [\"20231123_SNExp_18Bc_NP_SN2_R1\",\"20231123_SNExp_18Bc_NP_SN2_R2\",\"20231123_SNExp_18Bc_NP_SN2_R3\"]\n",
    "SN2_NP_matrix,SN2_NP_dbscan_matrix,SN2_NP_df = create_summed_matrix(SN2_wd,SN2_NP_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize intensity matrices of SN1-SN3\n",
    "SN3_wd = \"/home/stefan/Synology/Data_nano_ribolyzer/NP_IVPA_SN1-3_R10/\"\n",
    "\n",
    "SN3_IVPA_samples = [\"20231123_SNExp_18Bc_IVPA_SN3_R1\",\"20231123_SNExp_18Bc_IVPA_SN3_R2\",\"20231123_SNExp_18Bc_IVPA_SN3_R3\"]\n",
    "SN3_IVPA_matrix,SN3_IVPA_dbscan_matrix,SN3_IVPA_df = create_summed_matrix(SN3_wd,SN3_IVPA_samples)\n",
    "\n",
    "SN3_NP_samples = [\"20231123_SNExp_18Bc_NP_SN3_R1\",\"20231123_SNExp_18Bc_NP_SN3_R2\",\"20231123_SNExp_18Bc_NP_SN3_R3\"]\n",
    "SN3_NP_matrix,SN3_NP_dbscan_matrix,SN3_NP_df = create_summed_matrix(SN3_wd,SN3_NP_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize intensity matrices of Cell Cytoplasm and Nucleus\n",
    "general_wd = \"/home/stefan/Synology/Data_nano_ribolyzer/NP_IVPA_R10\"\n",
    "\n",
    "Nuc_IVPA_samples = [\"20230920_NucExp_IVPA_9bc_Nucleus1\",\"20230920_NucExp_IVPA_9bc_Nucleus2\",\"20230920_NucExp_IVPA_9bc_Nucleus3\"]\n",
    "Nuc_IVPA_matrix,Nuc_IVPA_dbscan_matrix,Nuc_IVPA_df = create_summed_matrix(general_wd,Nuc_IVPA_samples)\n",
    "\n",
    "Nuc_NP_samples = [\"20231214_NucExp_NP_R10_Nuc_R1\",\"20231214_NucExp_NP_R10_Nuc_R2\",\"20231214_NucExp_NP_R10_Nuc_R3\"]\n",
    "Nuc_NP_matrix,Nuc_NP_dbscan_matrix,Nuc_NP_df = create_summed_matrix(general_wd,Nuc_NP_samples)\n",
    "\n",
    "Cyt_IVPA_samples = [\"20230920_NucExp_IVPA_9bc_Cytoplasm1\",\"20230920_NucExp_IVPA_9bc_Cytoplasm2\",\"20230920_NucExp_IVPA_9bc_Cytoplasm3\"]\n",
    "Cyt_IVPA_matrix,Cyt_IVPA_dbscan_matrix,Cyt_IVPA_df = create_summed_matrix(general_wd,Cyt_IVPA_samples)\n",
    "\n",
    "Cyt_NP_samples = [\"20231214_NucExp_NP_R10_Cyt_R1\",\"20231214_NucExp_NP_R10_Cyt_R2\",\"20231214_NucExp_NP_R10_Cyt_R3\"]\n",
    "Cyt_NP_matrix,Cyt_NP_dbscan_matrix,Cyt_NP_df = create_summed_matrix(general_wd,Cyt_NP_samples)\n",
    "\n",
    "Cell_IVPA_samples = [\"20230920_NucExp_IVPA_9bc_Cell1\",\"20230920_NucExp_IVPA_9bc_Cell2\",\"20230920_NucExp_IVPA_9bc_Cell3\"]\n",
    "Cell_IVPA_matrix,Cell_IVPA_dbscan_matrix,Cell_IVPA_df = create_summed_matrix(general_wd,Cell_IVPA_samples)\n",
    "\n",
    "Cell_NP_samples = [\"20231214_NucExp_NP_R10_Cell_R1\",\"20231214_NucExp_NP_R10_Cell_R2\",\"20231214_NucExp_NP_R10_Cell_R3\"]\n",
    "Cell_NP_matrix,Cell_NP_dbscan_matrix,Cell_NP_df = create_summed_matrix(general_wd,Cell_NP_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_matrix_list = [UTP18_IVPA_Nuc_dbscan_matrix,Ctrl_IVPA_Nuc_dbscan_matrix]\n",
    "colors = [\"blue\", \"red\"]\n",
    "legend_names = [\"UTP18 IVPA Nuc\",\"Ctrl IVPA Nuc\"]\n",
    "plot_matrix(legend_names,summed_matrix_list,colors,template_name,\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_matrix_list = [Las1L_IVPA_Nuc_dbscan_matrix,Ctrl_IVPA_Nuc_dbscan_matrix]\n",
    "colors = [\"blue\", \"red\"]\n",
    "legend_names = [\"Las1L IVPA Nuc\",\"Ctrl IVPA Nuc\"]\n",
    "plot_matrix(legend_names,summed_matrix_list,colors,template_name,\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_matrix_list = [SN1_NP_dbscan_matrix,SN2_NP_dbscan_matrix,SN3_NP_dbscan_matrix]\n",
    "colors = [\"blue\", \"red\",\"green\"]\n",
    "legend_names = [\"SN1 NP\",\"SN2 NP\",\"SN3 NP\"]\n",
    "plot_matrix(legend_names,summed_matrix_list,colors,template_name,\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_matrix_list = [SN1_IVPA_dbscan_matrix,SN2_IVPA_dbscan_matrix,SN3_IVPA_dbscan_matrix]\n",
    "colors = [\"blue\", \"red\",\"green\"]\n",
    "legend_names = [\"SN1 IVPA\",\"SN2 IVPA\",\"SN3 IVPA\"]\n",
    "plot_matrix(legend_names,summed_matrix_list,colors,template_name,\"./\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_matrix(\n",
    "    matrix_samples=[Ctrl_IVPA_Nuc_matrix,UTP18_IVPA_Nuc_matrix,WBSCR22_IVPA_Nuc_matrix,Las1L_IVPA_Nuc_matrix],\n",
    "    condition_samples=[\"Ctrl IVPA\",\"UTP18 IVPA\",\"WBSCR22 IVPA\",\"Las1L IVPA\"], \n",
    "    color_samples = [\"blue\",\"magenta\",\"cyan\",\"orange\"],\n",
    "    template_df_name=template_name, \n",
    "    with_lines=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_matrix(\n",
    "    matrix_samples=[Ctrl_IVPA_Nuc_matrix,UTP18_IVPA_Nuc_matrix],\n",
    "    condition_samples=[\"Ctrl IVPA\",\"UTP18 IVPA\"], \n",
    "    color_samples = [\"blue\",\"red\"],\n",
    "    template_df_name=template_name, \n",
    "    with_lines=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_matrix(\n",
    "    matrix_samples=[Ctrl_IVPA_Nuc_matrix],\n",
    "    condition_samples=[\"Ctrl IVPA\"], \n",
    "    color_samples = [\"blue\"],\n",
    "    template_df_name=template_name, \n",
    "    with_lines=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_matrix(\n",
    "    matrix_samples=[Ctrl_IVPA_Nuc_matrix,WBSCR22_IVPA_Nuc_matrix],\n",
    "    condition_samples=[\"Ctrl IVPA\",\"WBSCR22 IVPA\"], \n",
    "    color_samples = [\"blue\",\"red\"],\n",
    "    template_df_name=template_name, \n",
    "    with_lines=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_matrix(\n",
    "    matrix_samples=[Ctrl_IVPA_Nuc_matrix,Las1L_IVPA_Nuc_matrix],\n",
    "    condition_samples=[\"Ctrl IVPA\",\"Las1L IVPA\"], \n",
    "    color_samples = [\"blue\",\"red\"],\n",
    "    template_df_name=template_name, \n",
    "    with_lines=False\n",
    "    )\n",
    "#4285F4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_matrix(\n",
    "    matrix_samples=[Ctrl_NP_Nuc_matrix,UTP18_NP_Nuc_matrix,WBSCR22_NP_Nuc_matrix,Las1L_NP_Nuc_matrix],\n",
    "    condition_samples=[\"Ctrl NP\",\"UTP18 NP\",\"WBSCR22 NP\",\"Las1L NP\"], \n",
    "    color_samples = [\"blue\",\"magenta\",\"cyan\",\"orange\"],\n",
    "    template_df_name=template_name, \n",
    "    with_lines=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_matrix(\n",
    "    matrix_samples=[Ctrl_NP_Nuc_matrix,UTP18_NP_Nuc_matrix],\n",
    "    condition_samples=[\"Ctrl NP\",\"UTP18 NP\"], \n",
    "    color_samples = [\"blue\",\"red\"],\n",
    "    template_df_name=template_name, \n",
    "    with_lines=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_matrix(\n",
    "    matrix_samples=[Ctrl_NP_Nuc_matrix,WBSCR22_NP_Nuc_matrix],\n",
    "    condition_samples=[\"Ctrl NP\",\"WBSCR22 NP\"], \n",
    "    color_samples = [\"blue\",\"red\"],\n",
    "    template_df_name=template_name, \n",
    "    with_lines=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_matrix(\n",
    "    matrix_samples=[Ctrl_NP_Nuc_matrix,Las1L_NP_Nuc_matrix],\n",
    "    condition_samples=[\"Ctrl NP\",\"Las1L NP\"], \n",
    "    color_samples = [\"blue\",\"red\"],\n",
    "    template_df_name=template_name, \n",
    "    with_lines=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot function\n",
    "import pysam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def boxplot_bamstats(bamfile_paths:list,exp_conditions:list,reference_path:str,literature_mod_df_path:str):\n",
    "    literature_mod_df = pd.read_csv(literature_mod_df_path ,sep=\"\\t\",header=None,index_col=None) #\"/home/stefan/wf-nanoribolyzer/references/rRNA_modifications_conv.bed\"\n",
    "    literature_mod_df.columns = [\"reference\",\"start\",\"end\",\"modification\",\"A\",\"B\",\"C\"]\n",
    "    fasta_file = pysam.FastaFile(reference_path)\n",
    "    reference = fasta_file.references[0]\n",
    "    reference_sequence = str(fasta_file.fetch(reference))\n",
    "    list_of_modification_ratios = []\n",
    "    for bamfile_path,exp_condition in zip(bamfile_paths,exp_conditions):\n",
    "        bamfile = pysam.AlignmentFile(bamfile_path, mode=\"rb\")\n",
    "        #iterator = 0            \n",
    "        for i in tqdm(bamfile.fetch(until_eof=True)):\n",
    "            #iterator += 1\n",
    "            #if iterator >= 1001:\n",
    "                #break\n",
    "            modification_dict = {}\n",
    "            for modification in np.unique(literature_mod_df[\"modification\"]):\n",
    "                #print(modification)\n",
    "                modification_dict[modification] = [0,0,0,0,0,[]]\n",
    "            if i.is_supplementary:\n",
    "                continue\n",
    "            try:\n",
    "                aligned_pairs = i.get_aligned_pairs(with_seq=True)\n",
    "                alignment_dict = {}\n",
    "                minimum = i.reference_start\n",
    "                maximum = i.reference_end\n",
    "                temp_mod_df = literature_mod_df\n",
    "                temp_mod_df = literature_mod_df[literature_mod_df[\"start\"] >= minimum]\n",
    "                #print(temp_mod_df)\n",
    "                #print(maximum)\n",
    "                temp_mod_df = temp_mod_df[temp_mod_df[\"end\"] <= maximum]\n",
    "                #print(temp_mod_df.shape)\n",
    "                last_valid_ref_pos = 1000000000\n",
    "                for query_pos, ref_pos, base in aligned_pairs:\n",
    "                    #if query_pos == None or ref_pos == None:\n",
    "                    #print(query_pos, ref_pos, base, i.get_forward_sequence()[query_pos])\n",
    "                    if temp_mod_df.shape[0] == 0:\n",
    "                        break\n",
    "                    if ref_pos is not None:\n",
    "                        last_valid_ref_pos = ref_pos\n",
    "                        if ref_pos > max(temp_mod_df[\"end\"]):\n",
    "                            continue\n",
    "                        if ref_pos < min(temp_mod_df[\"start\"]):\n",
    "                            continue\n",
    "                    for start,end,modification in zip(temp_mod_df[\"start\"],temp_mod_df[\"end\"],temp_mod_df[\"modification\"]):\n",
    "                        #try:\n",
    "                        if query_pos is None and ref_pos is None:\n",
    "                            break\n",
    "                        elif ref_pos is None and query_pos is not None: \n",
    "                            if start - 1 <= last_valid_ref_pos <= end + 1:\n",
    "                                #Base Quality record\n",
    "                                quality = i.query_qualities[query_pos]\n",
    "                                modification_dict[modification][5].append(float(quality))\n",
    "                                #Insertion\n",
    "                                #print(\"Insertion\")\n",
    "                                modification_dict[modification][0] = modification_dict[modification][0] + 1\n",
    "                                modification_dict[modification][1] = modification_dict[modification][1] + 1\n",
    "                                last_valid_ref_pos = 1000000000\n",
    "                                break\n",
    "                        elif query_pos is None and ref_pos is not None:\n",
    "                            if start <= ref_pos <= end:\n",
    "                                #Deletion\n",
    "                                #print(\"Deletion\")\n",
    "                                modification_dict[modification][0] = modification_dict[modification][0] + 1\n",
    "                                modification_dict[modification][2] = modification_dict[modification][2] + 1\n",
    "                                last_valid_ref_pos = 1000000000\n",
    "                                break\n",
    "                        elif query_pos is not None and ref_pos is not None:\n",
    "                            if start <= ref_pos <= end:\n",
    "                                #Base Quality record\n",
    "                                modification_dict[modification][0] = modification_dict[modification][0] + 1\n",
    "                                quality = i.query_qualities[query_pos]\n",
    "                                modification_dict[modification][5].append(float(quality))\n",
    "                                #Missmatch\n",
    "                                if str(base).islower():\n",
    "                                    #print(\"Missmatch\")\n",
    "                                    #print(query_pos, ref_pos, base, i.get_forward_sequence()[query_pos], start, end)\n",
    "                                    modification_dict[modification][3] = modification_dict[modification][3] + 1\n",
    "                                    last_valid_ref_pos = 1000000000\n",
    "                                    break\n",
    "                                #Match\n",
    "                                elif str(base).isupper():\n",
    "                                    #print(\"Match\")\n",
    "                                    modification_dict[modification][4] = modification_dict[modification][4] + 1\n",
    "                                    last_valid_ref_pos = 1000000000\n",
    "                                    break\n",
    "            except TypeError:\n",
    "                #print(\"Aligned pairs were NoneType\")\n",
    "                continue\n",
    "            for modification in np.unique(literature_mod_df[\"modification\"]):\n",
    "                        modification_entry = modification_dict[modification]\n",
    "                        if modification_entry[0] != 0:\n",
    "                            mod_list_for_df = [\n",
    "                                modification_entry[0],\n",
    "                                modification_entry[1],\n",
    "                                modification_entry[1]/modification_entry[0],\n",
    "                                modification_entry[2],\n",
    "                                modification_entry[2]/modification_entry[0],\n",
    "                                modification_entry[3],\n",
    "                                modification_entry[3]/modification_entry[0],\n",
    "                                modification_entry[4],\n",
    "                                modification_entry[4]/modification_entry[0],\n",
    "                                np.mean(np.array(modification_entry[5])),\n",
    "                                modification,\n",
    "                                i.query_name,\n",
    "                                exp_condition\n",
    "                            ]\n",
    "                            list_of_modification_ratios.append(mod_list_for_df)\n",
    "    modification_ratio_df = pd.DataFrame(list_of_modification_ratios,\n",
    "                                         columns=\n",
    "                                            [\n",
    "                                             \"n_modification\",\n",
    "                                             \"insertion\",\n",
    "                                             \"insertion_freq\",\n",
    "                                             \"deletion\",\n",
    "                                             \"deletion_freq\",\n",
    "                                             \"missmatch\",\n",
    "                                             \"missmatch_freq\",\n",
    "                                             \"match\",\n",
    "                                             \"match_freq\",\n",
    "                                             \"mean_quality\",\n",
    "                                             \"modification_type\",\n",
    "                                             \"read_id\",\n",
    "                                             \"experimental_condition\"\n",
    "                                             ]\n",
    "                                         )\n",
    "    modification_ratio_df.to_csv(\"./bamstats.csv\",sep=\";\",header=True,index=None)\n",
    "    #print(modification_ratio_df[modification_ratio_df[\"experimental_condition\"] == \"NP Cyt\"])\n",
    "    #print(modification_ratio_df[modification_ratio_df[\"experimental_condition\"] == \"IVT 18S\"])\n",
    "    return modification_ratio_df\n",
    "\n",
    "def plot_boxplot(modification_df:pd.DataFrame):\n",
    "    #print(np.unique(modification_df[\"modification_type\"]))\n",
    "    fig,axs = plt.subplots(nrows=len(np.unique(modification_df[\"modification_type\"])),ncols=5,figsize = (40,40))\n",
    "    for index,val in enumerate(np.unique(modification_df[\"modification_type\"])):\n",
    "        for index2,val2 in enumerate([\"mean_quality\",\"insertion_freq\",\"deletion_freq\",\"missmatch_freq\",\"match_freq\"]):\n",
    "            temp_ax = axs[index,index2]\n",
    "            temp_modification_df =  modification_df[modification_df[\"modification_type\"] == val]\n",
    "            sns.violinplot(x=temp_modification_df[\"experimental_condition\"],y=temp_modification_df[val2],hue=temp_modification_df[\"experimental_condition\"],ax=temp_ax,alpha=0.5)\n",
    "            sns.boxplot(x=temp_modification_df[\"experimental_condition\"],y=temp_modification_df[val2],hue=temp_modification_df[\"experimental_condition\"],ax=temp_ax,whis=(0, 100))\n",
    "            temp_ax.set_ylabel(val2.replace(\"_\",\" \"))\n",
    "            temp_ax.set_xlabel(\"\")\n",
    "            if val2 == \"mean_quality\":\n",
    "                temp_ax.set_ylim((-5,55))\n",
    "            else:\n",
    "                temp_ax.set_ylim((-0.2,1.2))\n",
    "            if index2 == 0:\n",
    "                temp_ylabel = val2.replace(\"_\",\" \")\n",
    "                temp_ax.set_ylabel(f\"{val}\\n{temp_ylabel}\")\n",
    "    fig.savefig(f\"quality_indel_match_boxplot.svg\",format=\"svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(modification_ratio_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "other_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
